### âœ… **String Functions Used**

---

### ðŸ”¹ In **SQL**:

* `LOWER()` â€“ converts to lowercase
* `UPPER()` â€“ converts to uppercase
* `LTRIM()` / `RTRIM()` / `TRIM()` â€“ remove spaces
* `SUBSTR()` / `SUBSTRING()` â€“ extract substring
* `LENGTH()` â€“ string length
* `INSTR()` â€“ position of substring
* `REPLACE()` â€“ replace substring
* `CONCAT()` / `||` â€“ string concatenation
* `LIKE`, `ILIKE` â€“ pattern matching
* `REGEXP_LIKE()` â€“ regex match
* `CAST()` â€“ convert datatype (e.g. string to int)

---

### ðŸ”¹ In **PySpark** (`pyspark.sql.functions`):

* `lower(col)` / `upper(col)`
* `ltrim(col)` / `rtrim(col)` / `trim(col)`
* `length(col)`
* `substring(col, pos, len)`
* `instr(col, substr)`
* `regexp_replace(col, pattern, replacement)`
* `regexp_extract(col, pattern, idx)`
* `concat(col1, col2, ...)`
* `concat_ws(separator, col1, col2, ...)`
* `translate(col, from_str, to_str)`
* `initcap(col)` â€“ capitalize first letter of each word
* `reverse(col)` â€“ reverse the string
* `split(col, pattern)` â€“ split string to array
* `locate(substr, str)` â€“ position of substring

Let me know if you want syntax or examples for any.
